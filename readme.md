# Описание

Решение выполненно в микросервесной архитектуре. Если нагрузка возрастет, то есть возмодность поднять несколько api и ml worker`ов для ее распределения и попросить nginx быть балансировщиком.

FastApi -  выбран фреймворком для API потому, для данной задачи он хорошо подходит и не тянет за собой кучу зависимостей. Так же документация к API генерируется автоматом ее можно посмотреть  по пути (если локальный запуск) 127.0.0.1/docs
В качестве очереди выбран Redis. После того как подадает информация в очередь, первый же свободный ml воркер беред задачу в работу и в последующем отправляет результаты в PostgreSQL и сохраняет в кэш результаты по определенной заявки на распознание

Все необходимые данные для работы сервисов между собой вынесены в переменные окружения, которые прокидывают в контейнеры при страрте
